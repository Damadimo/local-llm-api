# Server Configuration
HOST=127.0.0.1
PORT=8000
RELOAD=false
DEBUG=false
LOG_LEVEL=INFO

# Model Configuration
MODEL_REPO_ID=TheBloke/Llama-2-7B-Chat-GGUF
MODEL_FILENAME=llama-2-7b-chat.Q4_K_M.gguf
# MODEL_PATH=/path/to/your/model.gguf  # Optional: direct path to model

# LLM Generation Settings
MAX_TOKENS=256
TEMPERATURE=0.2
CONTEXT_LENGTH=512

# Embedding Settings
EMBEDDING_MODEL_NAME=jinaai/jina-embeddings-v3
EMBEDDING_DIMENSION=1024

# Vector Store Settings
QDRANT_HOST=localhost
QDRANT_PORT=6333
QDRANT_COLLECTION_NAME=knowledge_base
QDRANT_USE_MEMORY=true

# RAG Settings
RAG_TOP_K=3
RAG_SCORE_THRESHOLD=0.7

# Paths (relative to project root)
DATA_DIR=data
MODELS_DIR=data/models
KNOWLEDGE_DIR=data/knowledge 